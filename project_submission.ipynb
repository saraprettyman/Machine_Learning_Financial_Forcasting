{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4320 Introduction to Machine Learning\n",
    "\n",
    "**Please type your group name here:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupName = \"NoProblem\"\n",
    "assert GroupName != \"\", 'Please enter your name in the above quotation marks, thanks!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Understanding the problem](#1)\n",
    "2. [Imports](#2)\n",
    "   1. [Importing Packages](#2a)\n",
    "   2. [Data splitting](#2b)\n",
    "3. [EDA](#3)\n",
    "4. [Feature engineering](#4)\n",
    "5. [Preprocessing and transformations](#5)\n",
    "6. [Baseline model](#6)\n",
    "7. [Linear models](#7)\n",
    "8. [Different models](#8)\n",
    "9. [Feature selection](#9)\n",
    "10. [Hyperparameter optimization](#10)\n",
    "11. [Interpretation and feature importances](#11)\n",
    "12. [Results on the test set](#12)\n",
    "13. [Submit the predictions to Kaggle](#13)\n",
    "14. [Your takeaway from the course](#14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 1 Prediction Problem and Explaination <a name=\"1\"></a>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Spend some time understanding the problem and what each feature means. Write a few sentences on your initial thoughts on the problem and the dataset.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is to forecast store sales for _Corporaci√≥n Favorita_, a large Ecuadorian-based grocery retailer. The goal is to use previous sales data. The previously sales data is _family_ category which has a _store_nbr_, total number of items in that category that were _onpromotion_ that day, the specific date, and the total items sold that day for that family. The dates are able to be cross referenced with holidays in order to get a better time prediction. The family I am assuming will be very time dependent as needed change over the course of the year and many sales in my experience are holiday dependent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Imports <a name=\"2\"></a>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a Importing Packages <a name=\"2a\"></a>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Import all necessary packages**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2b Data splitting <a name=\"2b\"></a>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Split the data into train and test portions. Note that the test.csv is the end file to test, not the data split for testing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('data/train.csv')\n",
    "final_test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets (in this case test_df is our validation set)\n",
    "train_df, test_df = train_test_split(dataset_df, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 3. EDA <a name=\"3\"></a>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform exploratory data analysis on the train set, including summary statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_df.head())\n",
    "display(train_df.info())\n",
    "\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "display(\"Numerical Data Description\")\n",
    "display(train_df.describe(include=['int64', 'float64']))\n",
    "\n",
    "display(\"Categorical Data Description\")\n",
    "display(train_df.describe(include=['object', 'datetime64'], datetime_is_numeric=True))\n",
    "\n",
    "display(\"Family (Category) Counts\")\n",
    "display(train_df['family'].value_counts())\n",
    "\n",
    "display(\"First and last date\")\n",
    "display(train_df['date'].min())\n",
    "display(train_df['date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Summary Statistics_\n",
    "\n",
    "1. Here, we can see that there are 2 discrete varaibles: _date_ (1684 dates ranging from 2013 to 2016) and _family_ (33 unique family categories which have near equal statified counts).\n",
    "2. The rest of the variables are numerical: id (unique identifier, discrete), store_nbr (1-54, discrete), sales (appears to be skewed, need to see visualization, continuous), and onpromotion (appears to be skewed, need to see visualization).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Visual Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eda_df = train_df.copy(deep=True)\n",
    "\n",
    "# Create bar plot for 'date'\n",
    "freq_df = eda_df['date'].value_counts().reset_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='index', y='date', data=freq_df)\n",
    "plt.title('Bar plot of date')\n",
    "plt.xlabel('date')\n",
    "plt.xticks(np.arange(0, len(freq_df['index']), step=200), rotation=90)\n",
    "plt.text(0.5, -0.30, 'Figure 1', transform=plt.gca().transAxes, ha='center', va='center', fontsize=12, style='italic')\n",
    "plt.show()\n",
    "\n",
    "# Create bar plot for 'store_nbr'\n",
    "freq_df = eda_df['store_nbr'].value_counts().reset_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='index', y='store_nbr', data=freq_df)\n",
    "plt.title('Bar plot of store_nbr')\n",
    "plt.xlabel('store_nbr')\n",
    "plt.xticks(rotation=90)\n",
    "plt.text(0.5, -0.15, 'Figure 2', transform=plt.gca().transAxes, ha='center', va='center', fontsize=12, style='italic')\n",
    "plt.show()\n",
    "\n",
    "# Create bar plot for 'family'\n",
    "freq_df = eda_df['family'].value_counts().reset_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='index', y='family', data=freq_df)\n",
    "plt.title('Bar plot of family')\n",
    "plt.xlabel('family')\n",
    "plt.xticks(rotation=90)\n",
    "plt.text(0.5, -0.55, 'Figure 3', transform=plt.gca().transAxes, ha='center', va='center', fontsize=12, style='italic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Figures 1,2, and 3, we are shown that _family_, _date_, and _store_nbr_ are all generally stratified. This is good as it means that we have a good distribution of data for each of these variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all sales \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['sales'], bins=20)\n",
    "plt.title('Histogram of Sales')\n",
    "plt.xlabel('Sales', fontsize=12)\n",
    "plt.text(0.5, -0.15, 'Figure 4', transform=plt.gca().transAxes, ha='center', va='center', fontsize=12, style='italic')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Show all onpromotion\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['onpromotion'], bins=20)\n",
    "plt.title('Histogram of Onpromotion')\n",
    "plt.xlabel('Onpromotion', fontsize=12)\n",
    "plt.text(0.5, -0.15, 'Figure 5', transform=plt.gca().transAxes, ha='center', va='center', fontsize=12, style='italic')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONPROMOTION INVESTIGATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Test to see if Onpromotion should be kept'''\n",
    "corr_matrix = train_df.corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='Blues')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.text(0.5, -0.15, 'Figure 6', transform=plt.gca().transAxes, ha='center', va='center', fontsize=12, style='italic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_onpromotion_ in Figure 6 has the highest correlation to sales, incidating it should be kept.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' We will test the Onpromotion variable, since it is an independent varaible, \n",
    "to see if Feature Cutting should be used. The feature cut would be the upper quantile'''\n",
    "\n",
    "onpromo_zero_cnt = len(train_df[train_df['onpromotion'] == 0])\n",
    "ratio = onpromo_zero_cnt / len(train_df)\n",
    "print(\"Ratio of Zero in Onpromotion: {:.2f}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Since Ratio is too high, we will not use Feature Cutting and instead use ln(1+x) transformation to normalize the data, \n",
    "then use StandardScalar Feature Scaling in preprocessing. Until Feature Engineering, we will use the copy dateframe, eda_df''' \n",
    "eda_df['onpromotion'] = np.log1p(eda_df['onpromotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(eda_df['onpromotion'], bins=20)\n",
    "plt.title('Histogram of Onpromotion')\n",
    "plt.xlabel('Onpromotion', fontsize=12)\n",
    "plt.text(0.5, -0.15, 'Figure 7', transform=plt.gca().transAxes, ha='center', va='center', fontsize=12, style='italic')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SALES INVESTIGATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Test to see sales upper quantile significance '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' For sales, since it is the dependent variable, Feature Cutting is not the first choice. Observing that the upper quantile of _sales_ is significant, we will apply a transformation to normalize the data, then use StandardScalar Feature Scaling in preprocessing'''\n",
    "eda_df['sales'] = np.log1p(eda_df['sales'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['sales'], bins=20)\n",
    "plt.title('Histogram of Sales')\n",
    "plt.xlabel('Sales', fontsize=12)\n",
    "plt.text(0.5, -0.15, 'Figure 8', transform=plt.gca().transAxes, ha='center', va='center', fontsize=12, style='italic')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log(1+x) did not do much for _onpromotion_ and _sales_, showing that StandardScalar may not be the better scalar to use, and MinMax will need to be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram, seeing if some stores are more inclined to do promotions\n",
    "promotion_store = train_df[train_df['onpromotion'] != 0].groupby('store_nbr')['onpromotion'].count().reset_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=\"store_nbr\", y=\"onpromotion\", data=promotion_store)\n",
    "plt.title('Histogram of Onpromotion by Store Number')\n",
    "plt.xlabel('Store Number')\n",
    "plt.ylabel('Count of Promotions')\n",
    "plt.xticks(rotation=90)\n",
    "plt.text(0.5, -0.15, 'Figure 9', transform=plt.gca().transAxes, ha='center', va='center', fontsize=12, style='italic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix shows _store_nbr_ and _sales_ as not being correlated at all. It appears the _store_nbr_ is not a good predictor of _sales_, but _onpromotion_ is a good predictor of _sales_ and _onpromotion_ varies with _store_nbr_. So _store_nbr_ should be altered to a more relevent variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate year, month, and day from date\n",
    "eda_df['date'] = pd.to_datetime(eda_df['date'])\n",
    "eda_df['day'] = eda_df['date'].dt.strftime('%Y').astype(int)\n",
    "eda_df['month'] = eda_df['date'].dt.strftime('%m').astype(int)\n",
    "eda_df['year'] = eda_df['date'].dt.strftime('%d').astype(int)\n",
    "eda_df = eda_df.drop(columns=['date'])\n",
    "eda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = eda_df.drop(columns=['family', 'id']).corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='Blues')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.text(0.5, -0.15, 'Figure 10', transform=plt.gca().transAxes, ha='center', va='center', fontsize=12, style='italic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since this is a time-series problem, we will be putting a heavier emphasis on the _date_ variable by separating it into day, month, and year. Above, you can see it performed on the _eda_df_ which has been used for testing data augmentation without impacting the original dataset. Now, these changes can be applied in the feature engineering step., so that _date_ can be made more useful. Observe the .15 correlation between _day_ and _sales_. _store_nbr_ is still low and will be changed. _month_ and _year_ are also low, but will be kept for now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 4. Feature engineering <a name=\"4\"></a>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out feature engineering. In other words, extract new features relevant for the problem and work with your new feature set. You may have to go back and forth between feature engineering and preprocessing. Briefly explain why you come up with these new features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sales and onpromotion transformation\n",
    "train_df['onpromotion'] = np.log1p(train_df['onpromotion'])\n",
    "train_df['sales'] = np.log1p(train_df['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful CSV'set\n",
    "holiday_events_df = pd.read_csv('data/holidays_events.csv')\n",
    "stores_df = pd.read_csv('data/stores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the imported CVS's head\n",
    "display(holiday_events_df.head())\n",
    "display(stores_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate useful df's into smaller df's\n",
    "national_holiday_df = holiday_events_df[(holiday_events_df['locale'] == 'National') & (holiday_events_df['type'] == 'Holiday')]['date']\n",
    "national_not_holiday_df = holiday_events_df[(holiday_events_df['locale'] == 'National') & (holiday_events_df['type'] != 'Holiday')]['date']\n",
    "\n",
    "local_holiday_df = holiday_events_df[(holiday_events_df['locale'] == 'Local') & (holiday_events_df['type'] == 'Holiday')]['date']\n",
    "local_not_holiday_df = holiday_events_df[(holiday_events_df['locale'] == 'Local') & (holiday_events_df['type'] != 'Holiday')]['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holiday_transform(dataframe):\n",
    "    dataframe['national_holiday'] = dataframe['date'].isin(national_holiday_df).astype(int)\n",
    "    dataframe['national_not_holiday'] = dataframe['date'].isin(national_not_holiday_df).astype(int)\n",
    "    dataframe['local_holiday'] = dataframe['date'].isin(local_holiday_df).astype(int)\n",
    "    dataframe['local_not_holiday'] = dataframe['date'].isin(local_not_holiday_df).astype(int)\n",
    "    return dataframe\n",
    "\n",
    "def date_transform(dataframe):\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "    dataframe['day'] = dataframe['date'].dt.strftime('%Y')\n",
    "    dataframe['month'] = dataframe['date'].dt.strftime('%m')\n",
    "    dataframe['year'] = dataframe['date'].dt.strftime('%d')\n",
    "    dataframe = dataframe.drop(columns=['date'])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = date_transform(holiday_transform((train_df)))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 'store_nbr' based on what cluster, city, and state it is in\n",
    "def store_transform(dataframe):\n",
    "    dataframe['store_cluster'] = stores_df['cluster'].values[dataframe['store_nbr'].values - 1]\n",
    "    dataframe['city'] = stores_df['city'].values[dataframe['store_nbr'].values - 1]\n",
    "    dataframe['state'] = stores_df['state'].values[dataframe['store_nbr'].values - 1]\n",
    "    dataframe = dataframe.drop(columns=['store_nbr'])\n",
    "    return dataframe\n",
    "\n",
    "train_df = store_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display manual transformations so far\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Quick Feature Test'''\n",
    "corr_matrix = train_df.corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='Blues')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.text(0.5, -0.5, 'Figure 11', transform=plt.gca().transAxes, ha='center', va='center', fontsize=12, style='italic')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating Feature Vectors and Targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['sales'])\n",
    "y_train = train_df['sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 5. Preprocessing and transformations <a name=\"5\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying different feature types and the transformations to apply on each feature type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature List\n",
    "categorical_features = ['family', 'store_cluster', 'city', 'state'] # One Hot Encoded\n",
    "binary_features = ['national_holiday', 'national_not_holiday', 'local_holiday', 'local_not_holiday'] # One Hot Encoded (Binary)\n",
    "scaling_features = ['onpromotion', 'day', 'month', 'year'] # MinMax Scaled\n",
    "drop_features = ['id'] # Drop\n",
    "target = 'sales'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a column transformer and perform preprocessing on the train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "binary_transformer = OneHotEncoder(drop=\"if_binary\", dtype=int)\n",
    "scaling_transformer = StandardScaler()\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (binary_transformer, binary_features),\n",
    "    (scaling_transformer, scaling_features),\n",
    "    ('drop', drop_features),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = preprocessor.fit_transform(X_train)\n",
    "X_train_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = list(\n",
    "    preprocessor.named_transformers_[\"onehotencoder-1\"].get_feature_names_out(categorical_features)) + list(\n",
    "    preprocessor.named_transformers_[\"onehotencoder-2\"].get_feature_names_out(binary_features)) + scaling_features\n",
    "\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trained_transformed = pd.DataFrame(X_train_prepared, columns=column_names)\n",
    "X_trained_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 6. Baseline model <a name=\"6\"></a>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try `scikit-learn`'s baseline model and report results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(columns=['sales'])\n",
    "y_test = test_df['sales']\n",
    "\n",
    "y_test = np.log1p(y_test)\n",
    "X_test['onpromotion'] = np.log1p(X_test['onpromotion'])\n",
    "\n",
    "X_test_prep = store_transform(date_transform(holiday_transform((X_test))))\n",
    "X_test_prepared = preprocessor.transform(X_test_prep)\n",
    "X_test_transformed = pd.DataFrame(X_test_prepared, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use skikit learn baseline model for numerical variables\n",
    "dummy_reg = DummyRegressor(strategy=\"mean\")\n",
    "dummy_reg.fit(X_trained_transformed, y_train)\n",
    "dummy_reg.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 7. Linear models <a name=\"7\"></a>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try a linear model as a first real attempt.\n",
    "2. Carry out hyperparameter tuning to explore different values for the complexity hyperparameter.\n",
    "3. Report cross-validation scores along with standard deviation.\n",
    "4. Summarize your results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a model\n",
    "model = Ridge()\n",
    "model.fit(X_trained_transformed, y_train)\n",
    "model.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Hyperparameter tuning\n",
    "# Define the parameter grid\n",
    "param_grid = {'alpha': np.arange(0, 5, 0.1)}\n",
    "\n",
    "# Initialize the Randsearch object\n",
    "rand_search = RandomizedSearchCV(model, param_grid, cv=5, n_iter=20)\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the data\n",
    "rand_search.fit(X_trained_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best params: \", rand_search.best_params_)\n",
    "\n",
    "print(\"Best score: \", rand_search.best_score_)\n",
    "\n",
    "pd.DataFrame(rand_search.cv_results_)[\n",
    "    [\n",
    "        \"mean_test_score\",\n",
    "        \"param_alpha\",\n",
    "        \"mean_fit_time\",\n",
    "        \"rank_test_score\",\n",
    "    ]\n",
    "].set_index(\"rank_test_score\").sort_index().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validate with best params\n",
    "best_alpha = rand_search.best_params_.get('alpha')\n",
    "model = Ridge(alpha=best_alpha)\n",
    "cv_results = cross_validate(model, X_trained_transformed, y_train, cv=10, scoring='r2')\n",
    "print(\"CV Mean: \", cv_results['test_score'].mean())\n",
    "print(\"CV Std Dev: \", cv_results['test_score'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model is a good first attempt as it is simple and easy to understand and the standard deviation is very low. The hyperparameter tuning has cross validations scores that are lower than the inital ridge regression default. Overall this insinuates that the linear model might be a good fit for the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 8. Different models <a name=\"8\"></a>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try other models aside from a linear model. One of these models should be a tree-based ensemble model.\n",
    "2. Summarize your results in terms of overfitting/underfitting and fit and score times. Can you beat a linear model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfr = RandomForestRegressor(max_depth=10, n_estimators=15)\n",
    "#model_rfr.fit(X_trained_transformed, y_train)\n",
    "#model_rfr.score(X_test_transformed, y_test)\n",
    "rfr_cv = cross_validate(model_rfr, X_trained_transformed, y_train, scoring='r2', cv=3)\n",
    "print(\"CV Mean: \", rfr_cv['test_score'].mean())\n",
    "print(\"CV Std Dev: \", rfr_cv['test_score'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtr = DecisionTreeRegressor(max_depth=10)\n",
    "#model_dtr.fit(X_trained_transformed, y_train)\n",
    "#model_dtr.score(X_test_transformed, y_test)\n",
    "dtr_cv = cross_validate(model_dtr, X_trained_transformed, y_train, scoring='r2', cv=3)\n",
    "print(\"CV Mean: \", dtr_cv['test_score'].mean())\n",
    "print(\"CV Std Dev: \", dtr_cv['test_score'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as x\n",
    "model_xg = x.XGBRegressor()\n",
    "#model_xg.fit(X_trained_transformed, y_train)\n",
    "#model_xg.score(X_test_transformed, y_test)\n",
    "xg_cv = cross_validate(model_xg, X_trained_transformed, y_train, scoring='r2', cv=3)\n",
    "print(\"CV Mean: \", xg_cv['test_score'].mean())\n",
    "print(\"CV Std Dev: \", xg_cv['test_score'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 9. Feature selection <a name=\"9\"></a>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to select relevant features. Do the results improve with feature selection? Summarize your results. If you see improvements in the results, keep feature selection in your pipeline. If not, you may abandon it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_1 = make_pipeline(preprocessor, Ridge(alpha=1))\n",
    "lr_fitted_1 = lr_1.fit(X_train, y_train)\n",
    "x_train_enc_1 = lr_fitted_1.named_steps['columntransformer'].transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show multiple correlation matrices graphs, 4x2 grid\n",
    "fig, axs = plt.subplots(4, 2, figsize=(20, 20))\n",
    "cor_1 = pd.concat((pd.Series(y_train), pd.DataFrame(x_train_enc_2)), axis=1).iloc[:, :10].corr()\n",
    "cor_2 = pd.concat((pd.Series(y_train), pd.DataFrame(x_train_enc_2).iloc[:, 11:20]), axis=1).iloc[:, :10].corr()\n",
    "cor_3 = pd.concat((pd.Series(y_train), pd.DataFrame(x_train_enc_2).iloc[:, 21:30]), axis=1).iloc[:, :10].corr()\n",
    "cor_4 = pd.concat((pd.Series(y_train), pd.DataFrame(x_train_enc_2).iloc[:, 31:40]), axis=1).iloc[:, :10].corr()\n",
    "cor_5 = pd.concat((pd.Series(y_train), pd.DataFrame(x_train_enc_2).iloc[:, 41:50]), axis=1).iloc[:, :10].corr()\n",
    "cor_6 = pd.concat((pd.Series(y_train), pd.DataFrame(x_train_enc_2).iloc[:, 51:60]), axis=1).iloc[:, :10].corr()\n",
    "cor_7 = pd.concat((pd.Series(y_train), pd.DataFrame(x_train_enc_2).iloc[:, 61:70]), axis=1).iloc[:, :10].corr()\n",
    "cor_8 = pd.concat((pd.Series(y_train), pd.DataFrame(x_train_enc_2).iloc[:, 71:80]), axis=1).iloc[:, :10].corr()\n",
    "\n",
    "sns.heatmap(cor_1, ax=axs[0, 0], cmap='Blues', annot=True)\n",
    "sns.heatmap(cor_2, ax=axs[0, 1], cmap='Blues', annot=True)\n",
    "sns.heatmap(cor_3, ax=axs[1, 0], cmap='Blues', annot=True)\n",
    "sns.heatmap(cor_4, ax=axs[1, 1], cmap='Blues', annot=True)\n",
    "sns.heatmap(cor_5, ax=axs[2, 0], cmap='Blues', annot=True)\n",
    "sns.heatmap(cor_6, ax=axs[2, 1], cmap='Blues', annot=True)\n",
    "sns.heatmap(cor_7, ax=axs[3, 0], cmap='Blues', annot=True)\n",
    "sns.heatmap(cor_8, ax=axs[3, 1], cmap='Blues', annot=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "cor_9 = pd.concat((pd.Series(y_train), pd.DataFrame(x_train_enc_2).iloc[:, 81:90]), axis=1).iloc[:, :10].corr()\n",
    "cor_10 = pd.concat((pd.Series(y_train), pd.DataFrame(x_train_enc_2).iloc[:, 91:100]), axis=1).iloc[:, :10].corr()\n",
    "\n",
    "sns.heatmap(cor_9, ax=axs[0], cmap='Blues', annot=True)\n",
    "sns.heatmap(cor_10, ax=axs[1], cmap='Blues', annot=True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rest removing 'year'\n",
    "preprocessor_2 = make_column_transformer(\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (binary_transformer, binary_features),\n",
    "    (scaling_transformer, scaling_features[:-1]),\n",
    "    ('drop', drop_features),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "lr_2 = make_pipeline(preprocessor_2, KNeighborsRegressor(n_neighbors=5))\n",
    "lr_fitted_2 = lr_2.fit(X_train_dropped, y_train)\n",
    "x_train_enc_2 = lr_fitted_2.named_steps['columntransformer'].transform(X_train_dropped)\n",
    "pred_2 = lr_fitted_2.predict(x_test_without_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feats = ['family_GROCERY I',\n",
    "'family_BEVERAGES',\n",
    "'family_CLEANING',\n",
    "'family_DAIRY',\n",
    "'family_BREAD/BAKERY',\n",
    "'family_MEATS',\n",
    "'family_POULTRY',\n",
    "'family_PERSONAL CARE',\n",
    "'family_DELI',\n",
    "'family_PET SUPPLIES',\n",
    "'family_HARDWARE',\n",
    "'family_MAGAZINES',\n",
    "'family_HOME APPLIANCES',\n",
    "'family_SCHOOL AND OFFICE SUPPLIES',\n",
    "'family_BABY CARE',\n",
    "'family_BOOKS']\n",
    "\n",
    "X_feats = X_trained_transformed[best_feats]\n",
    "X_feats_test = X_test_transformed[best_feats]\n",
    "feats_boost = x.XGBRegressor()\n",
    "\n",
    "feats_boost.fit(X_feats, y_train)\n",
    "feats_scores = cross_validate(feats_boost, X_feats_test, y_test, cv=3, scoring='r2')\n",
    "print(\"CV Mean: \", feats_scores['test_score'].mean())\n",
    "print(\"CV Std Dev: \", feats_scores['test_score'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, eliminating features with lower coefficients isn't ideal here. This could be because of the sheer number of features created, since the sum total of many small coefficients can make a big difference. At least for a reasonably fast model like XGB or random forest, the trade off for eliminating features with coefficients below 2.0 is probably not worth it, despite the runtime improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 10. Hyperparameter optimization <a name=\"10\"></a>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods.\n",
    "\n",
    "- [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "- [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "- [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "import xgboost as x\n",
    "\n",
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "params = { # For XGBoost\n",
    "    \"learning_rate\": uniform(0.08, 0.13),\n",
    "    \"max_depth\": randint(2, 6),\n",
    "    \"n_estimators\": randint(80, 120),\n",
    "    \"subsample\": uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "model = x.XGBRegressor()\n",
    "\n",
    "# params = {\n",
    "#     \"max_depth\": randint(2, 6),\n",
    "#     \"n_estimators\": randint(20, 30)\n",
    "# }\n",
    "\n",
    "# model = RandomForestRegressor(random_state=42, )\n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(model, param_distributions=params, random_state=42, n_iter=10, cv=3, verbose=1, n_jobs=1, return_train_score=True, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X_trained_transformed, y_train)\n",
    "\n",
    "report_best_scores(search.cv_results_, 3)\n",
    "\n",
    "# XGBOOST HYPERPARAMETER TUNING RESULTS:\n",
    "# Model with rank: 1\n",
    "# Mean validation score: 0.709 (std: 0.035)\n",
    "# Parameters: {'learning_rate': 0.15782560294561476, 'max_depth': 4, 'n_estimators': 98, 'subsample': 0.6399899663272012}\n",
    "\n",
    "# Model with rank: 2\n",
    "# Mean validation score: 0.698 (std: 0.038)\n",
    "# Parameters: {'learning_rate': 0.20201185217204753, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8469926038510867}\n",
    "\n",
    "# Model with rank: 3\n",
    "# Mean validation score: 0.689 (std: 0.037)\n",
    "# Parameters: {'learning_rate': 0.20248622823903087, 'max_depth': 3, 'n_estimators': 88, 'subsample': 0.6063865008880857}\n",
    "\n",
    "# RANDOM FOREST HYPERPARAMETER TUNING RESULTS: \n",
    "# Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
    "# Model with rank: 1\n",
    "# Mean validation score: 0.155 (std: 0.045)\n",
    "# Parameters: {'max_depth': 4, 'n_estimators': 23}\n",
    "\n",
    "# Model with rank: 2\n",
    "# Mean validation score: 0.155 (std: 0.046)\n",
    "# Parameters: {'max_depth': 4, 'n_estimators': 26}\n",
    "\n",
    "# Model with rank: 3\n",
    "# Mean validation score: 0.154 (std: 0.046)\n",
    "# Parameters: {'max_depth': 4, 'n_estimators': 29}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 11. Interpretation and feature importances <a name=\"11\"></a>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Use the methods we saw in class (e.g., `eli5`, `shap`) (or any other methods of your choice) to examine the most important features of one of the non-linear models.\n",
    "2. Summarize your observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "X_train_enc = pd.DataFrame(\n",
    "    data=preprocessor.fit_transform(X_train),\n",
    "    columns=column_names,\n",
    "    index=X_train.index,\n",
    ")\n",
    "X_train_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "y_test_reset = y_test.reset_index(drop=True)\n",
    "y_test_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update here, file 15 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 12. Results on the test set <a name=\"12\"></a>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try your best performing model on the test data (from train test split) and report test scores.\n",
    "2. Do the test scores agree with the validation scores from before? To what extent do you trust your results? Do you think you've had issues with optimization bias?\n",
    "3. Take one or two test predictions and explain these individual predictions (e.g., with SHAP force plots).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "model_xg.fit(x_trained_transformed, y_train)\n",
    "best_scores = model_xg.score(x_test_transformed, y_test)\n",
    "print(best_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R2 score of the xgboost model seems to perform even better on the test set than the validation partitions. I suspect this is due to the validation sets being highly skewed, since even powerful ensemble models like random forest seemed to struggle with CV scores. Also, our final dataframe has a somewhat large amount of fields, so it is possible that there is very high variance within the validation sets, and that is also seen in the somewhat high standard deviations of CV scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 13. Submit the predictions to Kaggle <a name=\"13\"></a>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Retrain the best model on the whole training dataset and upload the predicted output on the test set to Kaggle. Report your final test score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "best_model = [-----]\n",
    "best_model.fit(X_train_prepared, y_train)\n",
    "\n",
    "y_pred = model.predict(final_test_df)\n",
    "\n",
    "results = pd.concat([test_df['id'], pd.Series(y_pred)], axis=1)\n",
    "results.columns = ['id', 'sales']\n",
    "results.to_csv('data/submission2_2.csv', index = False, header=True)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 14. Your takeaway <a name=\"14\"></a>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "What is your biggest takeaway from the supervised machine learning material we have learned so far? Please write thoughtful answers. Discuss other ideas that you did not try but could potentially improve the performance/interpretability .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
